---
sidebar_position: 2
title: config
ai_summary: "Workers configuration uses BullMQ. Psychic scans config on sync to capture workstream names for types. Extend ApplicationBackgroundedService and ApplicationScheduledService. Workstreams are groups containing a queue and workers. Multiple workstreams useful for rate-limited APIs. Supports BullMQ Pro for rate limiting."
---

# Workers - config

Psychic workers leverages [BullMQ](https://bullmq.io) under the hood to drive our background job systems. Our configuration largely circulates around arguments which would be directly provided to bullmq, but with some nuance, which is both due to the nature of the system being wrapped, as well as the fact that we desired a simpler configuration path for those not looking to leverage every possible bell and whistle, and really just looking to set up something simple.

## Types

Psychic scans your worker config whenever you run `pnpm psy sync`, capturing the workstream names you have configured for use when configuring your app. In order for these types to flow throughout your system, we recommend you add a few files to your file system.

> If you selected "yes" to background workers during the cli prompt, these files will already exist in your system.

```ts
// app/services/ApplicationBackgroundedService.ts

import { BaseBackgroundedService } from '@rvoh/psychic-workers'
import psychicTypes from '../../types/psychic'

export default class ApplicationBackgroundedService extends BaseBackgroundedService {
  public get psychicTypes() {
    return psychicTypes
  }
}
```

```ts
// app/services/ApplicationScheduledService.ts

import { BaseScheduledService } from '@rvoh/psychic-workers'
import psychicTypes from '../../types/psychic'

export default class ApplicationScheduledService extends BaseScheduledService {
  public get psychicTypes() {
    return psychicTypes
  }
}
```

You can now inherit from each of these classes in your application, allowing the types to flow gracefully through and protect you from making any mistakes:

## Workstreams

Psychic superimposes a new concept, called a `workstream`, on top of BullMQ's existing system, which enables one to easily grasp, configure, and express their background systems. In essence, you can think of a workstream as a group, containing a queue and a set of workers to work off that queue:

Many applications will only need one workstream, but multiple workstreams are extremely useful when, for example, you have background jobs responsible for hitting external APIs which are rate limited. Having a background system that doesn't respect rate limits can lead to real chaos in your systems, so it is useful to partition those out into their own workstreams. By doing so, you can ensure that only one worker is working off that queue, and you can either manually ensure that it breathes a certain amount of time before issuing another request, or else leverage [BullMQ Pro](https://docs.bullmq.io/bullmq-pro/introduction), which provides rate limiting tools out of the box that would enable you to spin up multiple workers on this workstream without concern of rate limit abuse.

To set up workstreams in Psychic, all you need to do is add a basic workstream setup to your `conf/workers.ts` file:

```ts
// conf/workers.ts

export default (workersApp: PsychicAppWorkers) => {
  workersApp.set('background', {
    defaultWorkstream: {
      // https://docs.bullmq.io/guide/parallelism-and-concurrency
      workerCount: os.cpus().length,
      concurrency: 100,
    },

    namedWorkstreams: [
      {
        name: 'NamedWorkstream',
        workerCount: 1,
      },

      // Rate limited workstream (requires BullMQ Pro)
      // {
      //   name: 'RateLimitedWorkstream',
      //   // https://docs.bullmq.io/guide/parallelism-and-concurrency
      //   workerCount: 1,
      //   concurrency: 100,
      //   rateLimit: {
      //     max: 100,
      //     duration: 1000,
      //   },
      // },
    ],

    providers: {
      Queue,
      Worker,
    },

    defaultBullMQQueueOptions: {
      defaultJobOptions: {
        removeOnComplete: 1000,
        removeOnFail: 20000,
        // 524,288,000 ms (~6.1 days) using algorithm:
        // "2 ^ (attempts - 1) * delay"
        attempts: 20,
        backoff: {
          type: 'exponential',
          delay: 1000,
        },
      },
    },

    // Any instance can push onto the queue
    defaultQueueConnection: AppEnv.isProduction
      ? new Cluster(
          [
            {
              host: AppEnv.string('BG_JOBS_REDIS_HOST'),
              port: AppEnv.integer('BG_JOBS_REDIS_PORT', { optional: true }) || 6379,
            },
          ],
          {
            slotsRefreshTimeout: 10000,
            dnsLookup: (address, callback) => callback(null, address),
            redisOptions: {
              username: AppEnv.string('BG_JOBS_REDIS_USERNAME'),
              password: AppEnv.string('BG_JOBS_REDIS_PASSWORD'),
              tls: {},
            },
            clusterRetryStrategy: (times: number) => Math.max(Math.min(Math.exp(times), 20000), 1000),
            enableOfflineQueue: false,
          }
        )
      : new Redis({
          host: AppEnv.string('BG_JOBS_REDIS_HOST', { optional: true }) || 'localhost',
          port: AppEnv.integer('BG_JOBS_REDIS_PORT', { optional: true }) || 6379,
          username: AppEnv.string('BG_JOBS_REDIS_USERNAME', { optional: true }),
          password: AppEnv.string('BG_JOBS_REDIS_PASSWORD', { optional: true }),
          // tls:  {},
          retryStrategy: (times: number) => Math.max(Math.min(Math.exp(times), 20000), 1000),
          enableOfflineQueue: false,
        }),

    // Only establish the worker Redis connection if on an instance that does the work
    defaultWorkerConnection: !AppEnv.boolean('WORKER_SERVICE')
      ? undefined
      : AppEnv.isProduction
      ? new Cluster(
          [
            {
              host: AppEnv.string('BG_JOBS_REDIS_HOST'),
              port: AppEnv.integer('BG_JOBS_REDIS_PORT', { optional: true }) || 6379,
            },
          ],
          {
            slotsRefreshTimeout: 15000,
            dnsLookup: (address, callback) => callback(null, address),
            redisOptions: {
              username: AppEnv.string('BG_JOBS_REDIS_USERNAME'),
              password: AppEnv.string('BG_JOBS_REDIS_PASSWORD'),
              tls: {},
              maxRetriesPerRequest: null,
            },
            clusterRetryStrategy: (times: number) => Math.max(Math.min(Math.exp(times), 20000), 1000),
          }
        )
      : new Redis({
          host: AppEnv.string('BG_JOBS_REDIS_HOST', { optional: true }) || 'localhost',
          port: AppEnv.integer('BG_JOBS_REDIS_PORT', { optional: true }) || 6379,
          username: AppEnv.string('BG_JOBS_REDIS_USERNAME', { optional: true }),
          password: AppEnv.string('BG_JOBS_REDIS_PASSWORD', { optional: true }),
          // tls:  {},
          maxRetriesPerRequest: null,
          retryStrategy: (times: number) => Math.max(Math.min(Math.exp(times), 20000), 1000),
        }),
  })
}
```

At first glance, this configuration might seem overwhelming to you, but most of this is just basic connection details for the queue and worker redis connections. Since bullmq runs on redis, you must provide redis connections for the queue and worker to leverage. Once the redis connections are set up, the only remaining thing to do is add a configuration for the default worker. Here is that section, isolated for you:

```ts
    defaultWorkstream: {
      // https://docs.bullmq.io/guide/parallelism-and-concurrency
      workerCount: os.cpus().length,
      concurrency: 100,
    },
```

With this done, any service in your application extending the `ApplicationBackgroundedService` or `ApplicationScheduledService` classes will automatically send their jobs to the queue belonging to the default workstream.

## Named workstreams

If your app demands multiple queues, you will want to leverage multiple workstreams. This will enable you to segment off groups of workers to work on one queue, and one group to work on the other. To do this, you can add a named workstream to the `conf/workers.ts` file:

```ts
    defaultWorkstream: {
      // https://docs.bullmq.io/guide/parallelism-and-concurrency
      workerCount: os.cpus().length,
      concurrency: 100,
    },
    namedWorkstreams: [
      {
        name: 'FileImport',
        workerCount: 1,
      },
    ]
```

With a named workstream added to your config, re-run `pnpm psy sync` to compile the latest psychic types. Once done, you will want to also adjust the background configuration for the services you wish to tap into this queue:

```ts
export default class FileImporter extends ApplicationBackgroundedService {
  public static get backgroundJobConfig(): BackgroundJobConfig<ApplicationBackgroundedService> {
    return { priority: 'not_urgent', workstream: 'FileImport' }
  }

  ...
}
```

## test invocation

By default, anything you push to the background will be immediately invoked in tests. You may find this behavior to be undesirable, preferring to actually push background work to bullmq in your app. In these cases, we provide special utilities that you can use during tests to help you manually simulate the role of a worker, enabling you to manually run jobs whenever you see fit.

To enable this behavior, you must set the `testInvocation` to `manual`, like so:

```ts
workersApp.set('testInvocation', 'manual')
```

Now you will be able to manually work off your queues using the `WorkerTestUtils`, exported from this package. For more information on testing with workers, see our [testing guides](/docs/plugins/workers/testing).
